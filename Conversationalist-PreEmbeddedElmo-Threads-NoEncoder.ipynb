{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import _dynet\n",
    "import sys \n",
    "sys.argv.append('--dynet-devices')\n",
    "sys.argv.append('GPU:0')\n",
    "dyparams = _dynet.DynetParams()\n",
    "\n",
    "# Fetch the command line arguments (optional)\n",
    "dyparams.from_args()\n",
    "\n",
    "# Set some parameters manualy (see the command line arguments documentation)\n",
    "dyparams.set_mem(2048*4)\n",
    "dyparams.set_random_seed(666)\n",
    "# Initialize with the given parameters\n",
    "dyparams.init() # or init_from_params(dyparams)\n",
    "\n",
    "import dynet as dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_file = 'elmo_embedded_training_data_merged_0_1.pkl'\n",
    "embedded_data = pickle.load(open(data_file,'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "type_vocab = set()\n",
    "for thread in embedded_data:\n",
    "    thread = thread[0]\n",
    "    for message,type,output in thread:\n",
    "        type_vocab |= set(type)\n",
    "        vocab |= set(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = set()\n",
    "safe = ['$&']\n",
    "for v in vocab:\n",
    "    if '[[' not in v and v not in safe:\n",
    "        to_remove.add(v)\n",
    "vocab -= to_remove\n",
    "\n",
    "vocab |= set(['<UNK>','True','False'])\n",
    "o2i = {o:i for i,o in enumerate(sorted(vocab))}\n",
    "i2o = {i:o for i,o in enumerate(sorted(vocab))}\n",
    "type_o2i = {o:i for i,o in enumerate(sorted(type_vocab))}\n",
    "type_i2o = {i:o for i,o in enumerate(sorted(type_vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "copy_data = []\n",
    "for thread in embedded_data:\n",
    "    thread_gen = []\n",
    "    thread_gc = []\n",
    "    thread_cop = []\n",
    "    text_thread = thread[0]\n",
    "    for message,type,output in text_thread:\n",
    "        gc = []\n",
    "        gen = []\n",
    "        cop = []\n",
    "        \n",
    "        for t in output:\n",
    "            t = t.replace('\\\\n','\\n')\n",
    "            ts = t.split('\\n\\n')\n",
    "            t = []\n",
    "            for t_ in ts:\n",
    "                t += t_.split('\\n')\n",
    "            ts = t\n",
    "            for t in ts:\n",
    "                if t == '':\n",
    "                    continue\n",
    "                if t in o2i:\n",
    "                    gc.append(0)\n",
    "                    gen.append(o2i[t])\n",
    "                    cop.append(0)\n",
    "                elif t not in message:\n",
    "                    gc.append(0)\n",
    "                    gen.append(o2i['<UNK>'])\n",
    "                    cop.append(0)\n",
    "                    \n",
    "                else:\n",
    "                    gc.append(1)\n",
    "                    gen.append(0)\n",
    "                    cop.append(message.index(t))\n",
    "        thread_gen.append(gen)\n",
    "        thread_gc.append(gc)\n",
    "        thread_cop.append(cop)\n",
    "        \n",
    "    all_data.append(list(zip([m[0] for m in thread[0]],[m[1] for m in thread[0]],[m[2] for m in thread[0]], thread[1],thread_gen,thread_gc,thread_cop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "class CopyNetwork:\n",
    "    def __init__(self, enc_layers, dec_layers, type_embeddings_size,embeddings_size, \n",
    "                 enc_state_size, dec_state_size, vocab_size, dropout = 0.1):\n",
    "        self.model = dy.Model()\n",
    "        self.type_embeddings = self.model.add_lookup_parameters((len(type_o2i), type_embeddings_size))\n",
    "        \n",
    "        # the rnns\n",
    "        self.DEC_RNN = dy.LSTMBuilder(dec_layers, type_embeddings_size+embeddings_size, dec_state_size, self.model)\n",
    "        self.DEC_RNN.set_dropout(dropout)\n",
    "        \n",
    "        # attention weights\n",
    "        self.attention_w1 = self.model.add_parameters(( type_embeddings_size+embeddings_size,  type_embeddings_size+embeddings_size))\n",
    "        self.attention_w2 = self.model.add_parameters(( type_embeddings_size+embeddings_size, dec_state_size))\n",
    "        self.attention_v = self.model.add_parameters((1,  type_embeddings_size+embeddings_size))\n",
    "\n",
    "        \n",
    "        self.copy_w1 = self.model.add_parameters(( type_embeddings_size+embeddings_size,  type_embeddings_size+embeddings_size))\n",
    "        self.copy_w2 = self.model.add_parameters(( type_embeddings_size+embeddings_size, dec_state_size))\n",
    "        self.copy_v = self.model.add_parameters((1,  type_embeddings_size+embeddings_size))\n",
    "\n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.mode_w = self.model.add_parameters((2, dec_state_size))\n",
    "        self.mode_b = self.model.add_parameters((2))\n",
    "        \n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.output_w = self.model.add_parameters((vocab_size, dec_state_size))\n",
    "        self.output_b = self.model.add_parameters((vocab_size))\n",
    "        \n",
    "        self.enc_state_size = enc_state_size\n",
    "        self.type_embeddings_size = type_embeddings_size\n",
    "        self.embeddings_size = embeddings_size\n",
    "    def _run_rnn(self, init_state, input_vecs):\n",
    "        s = init_state\n",
    "\n",
    "        states = s.add_inputs(input_vecs)\n",
    "        rnn_outputs = [s.output() for s in states]\n",
    "        return rnn_outputs\n",
    "    def _encode_string(self, embedded_string,RNN):\n",
    "        initial_state = RNN.initial_state()\n",
    "\n",
    "        # run_rnn returns all the hidden state of all the slices of the RNN\n",
    "        hidden_states = self._run_rnn(initial_state, embedded_string)\n",
    "\n",
    "        return hidden_states\n",
    "    \n",
    "    def _attend(self, input_vectors, state, w1, w2,v ):\n",
    "        attention_weights = []\n",
    "\n",
    "        w2dt = w2 * state.h()[-1]\n",
    "        for input_vector in input_vectors:\n",
    "            \n",
    "            attention_weight = v * dy.tanh(w1 * input_vector + w2dt)\n",
    "            attention_weights.append(attention_weight)\n",
    "        attention_weights = dy.softmax(dy.concatenate(attention_weights))\n",
    "\n",
    "        output_vectors = dy.esum(\n",
    "            [vector * attention_weight for vector, attention_weight in zip(input_vectors, attention_weights)])\n",
    "        return output_vectors, attention_weights\n",
    "   \n",
    "    def _embed(self,pos,pos_embed):\n",
    "        return [pos_embed[p] for p in pos]\n",
    "    \n",
    "    def get_probs(self, w, b, rnn):\n",
    "        return w*rnn+b\n",
    "    \n",
    "    def get_loss(self,initial_state, input_string,type_string,embedded_string,output_modes, output_generate, output_copy):\n",
    "        \n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        encoded_string = [dy.concatenate([e,self.type_embeddings[type_o2i[t]]]) for e,t in zip(embedded_string,type_string)]\n",
    "        if initial_state == None:\n",
    "            rnn_state = self.DEC_RNN.initial_state().add_input(dy.vecInput(self.type_embeddings_size+self.embeddings_size))\n",
    "        else:\n",
    "            rnn_state = initial_state\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        for mode,gen,copy in zip(output_modes,output_generate,output_copy):\n",
    "            attended_encoding,_ = self._attend(encoded_string, rnn_state, \n",
    "                                                       self.attention_w1, self.attention_w2,self.attention_v)\n",
    "            _,p_copy = self._attend(encoded_string, rnn_state, \n",
    "                                                       self.copy_w1, self.copy_w2,self.copy_v)\n",
    "            \n",
    "            rnn_state = rnn_state.add_input(attended_encoding)\n",
    "            \n",
    "            p_mode = self.get_probs(self.mode_w,self.mode_b,rnn_state.output())\n",
    "            \n",
    "            p_gen = self.get_probs(self.output_w,self.output_b,rnn_state.output())\n",
    "            \n",
    "            mult = False\n",
    "            if mult:\n",
    "                p_gen *= p_mode[0]\n",
    "                p_copy *= p_mode[1]\n",
    "            mode_err = dy.pickneglogsoftmax(p_mode, mode) \n",
    "            copy_err = dy.pickneglogsoftmax(p_copy,copy)  \n",
    "            gen_err = dy.pickneglogsoftmax(p_gen,gen)\n",
    "            if not mult:\n",
    "                losses.append(mode_err)\n",
    "            \n",
    "            if  mode == 0:\n",
    "                losses.append(gen_err)\n",
    "            else:\n",
    "                losses.append(copy_err)\n",
    "            if generate:\n",
    "                p_mode = p_mode.value()\n",
    "                p_copy = p_copy.value()\n",
    "                p_gen = p_gen.value()\n",
    "                if p_mode[0] > p_mode[1]:\n",
    "                    output.append(i2o[p_gen.index(max(p_gen))])\n",
    "                else:\n",
    "                    output.append(input_string[p_copy.index(max(p_copy))])\n",
    "        if generate:\n",
    "            print('IN:',' '.join(input_string))\n",
    "            print('OUT:',' '.join(output))\n",
    "            sys.stdout.flush()\n",
    "        return losses,rnn_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_network = CopyNetwork(3, 3,8, 1024, 1024, 1024, len(o2i),dropout = 0.25)\n",
    "lr = 0.01\n",
    "trainer = dy.AdamTrainer(copy_network.model,alpha = lr)\n",
    "copy_network.model.populate(f'Conversationalist_3_3_1024_1024_1024_History_{data_file.split(\".\")[0]}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "lr = 0.000005\n",
    "trainer.learning_rate = lr\n",
    "i = 0\n",
    "for epoch in range(500):\n",
    "    print(f'EPOCH {epoch}')\n",
    "    average = []\n",
    "    random.shuffle(all_data)\n",
    "    for thread in tqdm_notebook(all_data):\n",
    "        \n",
    "        dy.renew_cg()\n",
    "        previous_state = None\n",
    "        loss = []\n",
    "        for message in thread:\n",
    "            i += 1\n",
    "            #list(zip([m[0] for m in thread[0]],[m[1] for m in thread[0]], thread[1],thread_gen,thread_gc,thread_cop)))\n",
    "            \n",
    "            input_string,type_string, output_string, embedded_string,gen,gOrC, cop = message\n",
    "            loss_,previous_state = copy_network.get_loss(previous_state,input_string,type_string,embedded_string, gOrC,gen,cop)\n",
    "            loss += loss_\n",
    "        tot = len(loss)\n",
    "        loss = dy.esum(loss)\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "        average.append(loss.value()/tot)\n",
    "        if i > 100:\n",
    "\n",
    "            print(np.mean(average[:]),)\n",
    "            sys.stdout.flush()\n",
    "            i -= 100\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        lr = lr *0.97\n",
    "        print('decaying ', lr)\n",
    "        trainer.learning_rate = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_network.model.save(f'Conversationalist_3_3_1024_1024_1024_History_{data_file.split(\".\")[0]}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "elmo = ElmoEmbedder(options_file='~/DownloadedModels/Elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json',\n",
    "                    weight_file='~/DownloadedModels/Elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\n",
    "                    cuda_device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "i2o = {i:o for o,i in o2i.items()}\n",
    "\n",
    "\n",
    "def translate(model,initial_state, input_string,type_string,embedded_string,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        encoded_string = [dy.concatenate([e,model.type_embeddings[type_o2i[t]]]) for e,t in zip(embedded_string,type_string)]\n",
    "        if initial_state == None:\n",
    "            rnn_state = model.DEC_RNN.initial_state().add_input(dy.vecInput(model.type_embeddings_size+model.embeddings_size))\n",
    "        else:\n",
    "            rnn_state = initial_state\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        for _ in range(max_len):\n",
    "            attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.attention_w1, model.attention_w2,model.attention_v)\n",
    "            _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.copy_w1, model.copy_w2,model.copy_v)\n",
    "            \n",
    "            rnn_state = rnn_state.add_input(attended_encoding)\n",
    "            \n",
    "            p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "            \n",
    "            p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "            \n",
    "            p_mode = p_mode.value()\n",
    "            p_copy = p_copy.value()\n",
    "            p_gen = p_gen.value()\n",
    "            print(p_mode)\n",
    "            if p_mode[0] > p_mode[1]:\n",
    "                output.append(i2o[p_gen.index(max(p_gen))])\n",
    "            else:\n",
    "                output.append(input_string[p_copy.index(max(p_copy))])\n",
    "            if output[-1] == eos:\n",
    "                break\n",
    "        return output,rnn_state\n",
    "\n",
    "type_string = ['$FROM_FNAME', '$FROM_LNAME', '$FROM_EMAIL', '$TO_FNAME', '$TO_LNAME', '$TO_EMAIL', '$YEAR', '$MONTH', '$DAY', '$HOUR', '$MINUTE', '$GAP']\n",
    "sentence = ['John', 'Davin', 'LWmow@SMAqB.com', 'Steven', 'Smalley', 'oFDvG@kIrPz.com', '2019', '10', '9', '7', '43', '$N/A',\n",
    "            'I', 'hope', 'you', \"'re\", 'available', 'at', 'the', 'moment', 'for', 'a', 'task', '(', 'urgent', ')', '?',\n",
    "            '\\n\\n', 'Let', 'me', 'know', 'either', 'way', 'as', 'soon', 'as', 'possible', '.',\n",
    "            'I', 'urgently', 'need', 'you', 'to', 'buy', 'some', 'gift', 'cards', 'for', 'me', 'ASAP', '.', \n",
    "            'Please', 'confirm', 'that', 'you', \"'re\", 'on', 'this', '.', '\\n\\n', '-', 'John', '\\n\\n', 'Sent', 'from', 'my', 'iPhone']\n",
    "sentence = ['John', 'Davin', 'LWmow@SMAqB.com', 'Steven', 'Smalley', 'oFDvG@kIrPz.com', '2019', '10', '9', '7', '43', '$N/A',\n",
    "             'I', 'hope', 'you', \"'re\", 'available', 'at', 'the', 'moment', 'for', 'a', 'task', '(', 'urgent', ')', '?',\n",
    "            \n",
    "           ]\n",
    "\n",
    "type_string = type_string + ['$BODY']*(len(sentence)-len(type_string))\n",
    "embedded = elmo.embed_sentence(sentence)\n",
    "output, rnn_state = translate(copy_network, None, sentence,type_string,embedded)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
