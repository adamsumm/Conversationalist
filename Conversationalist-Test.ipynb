{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "import numpy as np\n",
    "easy = False\n",
    "if easy:\n",
    "    import dynet as dy\n",
    "else:\n",
    "    import _dynet\n",
    "    import sys \n",
    "    sys.argv.append('--dynet-devices')\n",
    "    sys.argv.append('GPU:0')\n",
    "    dyparams = _dynet.DynetParams()\n",
    "\n",
    "    # Fetch the command line arguments (optional)\n",
    "    dyparams.from_args()\n",
    "\n",
    "    # Set some parameters manualy (see the command line arguments documentation)\n",
    "    dyparams.set_mem(2048*4)\n",
    "    dyparams.set_random_seed(666)\n",
    "    # Initialize with the given parameters\n",
    "    dyparams.init() # or init_from_params(dyparams)\n",
    "\n",
    "    import dynet as dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "(i2o,o2i,type_o2i,type_i2o) = pickle.load(open('vocab.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "class CopyNetwork:\n",
    "    def __init__(self, enc_layers, dec_layers, type_embeddings_size,embeddings_size, \n",
    "                 enc_state_size, dec_state_size,output_embedding_size, vocab_size, dropout = 0):\n",
    "        self.model = dy.Model()\n",
    "        self.type_embeddings = self.model.add_lookup_parameters((len(type_o2i), type_embeddings_size))\n",
    "        self.output_embeddings = self.model.add_lookup_parameters((vocab_size, output_embedding_size))\n",
    "       \n",
    "        # the rnns\n",
    "        self.ENC_RNN_F = dy.LSTMBuilder(enc_layers, 1+type_embeddings_size+embeddings_size, enc_state_size/2, self.model)\n",
    "        self.ENC_RNN_F.set_dropout(dropout)\n",
    "        self.ENC_RNN_B = dy.LSTMBuilder(enc_layers, 1+type_embeddings_size+embeddings_size, enc_state_size/2, self.model)\n",
    "        self.ENC_RNN_B.set_dropout(dropout)\n",
    "        \n",
    "        self.DEC_RNN = dy.LSTMBuilder(dec_layers, enc_state_size+output_embedding_size+2, dec_state_size, self.model)\n",
    "        self.DEC_RNN.set_dropout(dropout)\n",
    "        \n",
    "        # attention weights\n",
    "        self.attention_w1 = self.model.add_parameters((enc_state_size, enc_state_size))\n",
    "        self.attention_w2 = self.model.add_parameters((enc_state_size, dec_state_size))\n",
    "        self.attention_v = self.model.add_parameters((1, enc_state_size))\n",
    "\n",
    "        \n",
    "        self.copy_w1 = self.model.add_parameters((enc_state_size, enc_state_size))\n",
    "        self.copy_w2 = self.model.add_parameters((enc_state_size, dec_state_size))\n",
    "        self.copy_v = self.model.add_parameters((1, enc_state_size))\n",
    "\n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.mode_w = self.model.add_parameters((2, dec_state_size))\n",
    "        self.mode_b = self.model.add_parameters((2))\n",
    "        \n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.output_w = self.model.add_parameters((vocab_size, dec_state_size))\n",
    "        self.output_b = self.model.add_parameters((vocab_size))\n",
    "        \n",
    "        self.enc_state_size = enc_state_size\n",
    "        self.type_embeddings_size = type_embeddings_size\n",
    "        self.embeddings_size = embeddings_size\n",
    "        self.output_embedding_size = output_embedding_size\n",
    "        \n",
    "    def load_weights(self,weight_file):\n",
    "        self.model.populate(weight_file)\n",
    "        \n",
    "    def _run_rnn(self, init_state, input_vecs):\n",
    "        s = init_state\n",
    "\n",
    "        states = s.add_inputs(input_vecs)\n",
    "        rnn_outputs = [s.output() for s in states]\n",
    "        return rnn_outputs\n",
    "    def _encode_string(self, embedded_string,RNN):\n",
    "        initial_state = RNN.initial_state()\n",
    "\n",
    "        # run_rnn returns all the hidden state of all the slices of the RNN\n",
    "        hidden_states = self._run_rnn(initial_state, embedded_string)\n",
    "\n",
    "        return hidden_states\n",
    "    \n",
    "    def _attend(self, input_vectors, state, w1, w2,v ):\n",
    "        attention_weights = []\n",
    "\n",
    "        w2dt = w2 * state.h()[-1]\n",
    "        for input_vector in input_vectors:\n",
    "            \n",
    "            attention_weight = v * dy.tanh(w1 * input_vector + w2dt)\n",
    "            attention_weights.append(attention_weight)\n",
    "        attention_weights = dy.softmax(dy.concatenate(attention_weights))\n",
    "\n",
    "        output_vectors = dy.esum(\n",
    "            [vector * attention_weight for vector, attention_weight in zip(input_vectors, attention_weights)])\n",
    "        return output_vectors, attention_weights\n",
    "   \n",
    "    def _embed(self,pos,pos_embed):\n",
    "        return [pos_embed[p] for p in pos]\n",
    "    \n",
    "    def get_probs(self, w, b, rnn):\n",
    "        return w*rnn+b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_network = CopyNetwork(3, 3,8, 1024, 1024, 1024, len(o2i),len(o2i),dropout = 0.25)\n",
    "copy_network.load_weights('Conversationalist_3_3_1024_1024_1024_elmo_embedded_training_data_merged_130k_0_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if easy:\n",
    "    elmo = ElmoEmbedder()\n",
    "else:\n",
    "    elmo = ElmoEmbedder(options_file='~/DownloadedModels/Elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json',\n",
    "                        weight_file='~/DownloadedModels/Elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\n",
    "                        cuda_device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "i2o = {i:o for o,i in o2i.items()}\n",
    "\n",
    "\n",
    "def translate(model,input_string,type_string,embedded_string,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        numbered = [is_number(s) for s in input_string]\n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           e,\n",
    "                                           model.type_embeddings[type_o2i[t]]]) for n,e,t in zip(numbered,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_string)]\n",
    "        encoded_string_f = model._encode_string(embedded_string,model.ENC_RNN_F)\n",
    "        encoded_string_b = model._encode_string(list(reversed(embedded_string)),model.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = model.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(model.enc_state_size+model.output_embedding_size+2)\n",
    "            )\n",
    "        for _ in range(max_len):\n",
    "            attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.attention_w1, model.attention_w2,model.attention_v)\n",
    "            _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.copy_w1, model.copy_w2,model.copy_v)\n",
    "            \n",
    "            mode_vec = np.zeros(2)\n",
    "            mode_vec[prev_mode] = 1\n",
    "            rnn_input = dy.concatenate([attended_encoding,\n",
    "                                        model.output_embeddings[prev_tok],\n",
    "                                        dy.inputTensor(mode_vec)\n",
    "                                       ])\n",
    "            \n",
    "            \n",
    "            \n",
    "            rnn_state = rnn_state.add_input(rnn_input)\n",
    "            \n",
    "            p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "            \n",
    "            p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "            \n",
    "            p_mode = p_mode.value()\n",
    "            p_copy = p_copy.value()\n",
    "            p_gen = p_gen.value()\n",
    "            \n",
    "            \n",
    "            if p_mode[0] > p_mode[1]:\n",
    "                prev_mode = 0\n",
    "                prev_tok = p_gen.index(max(p_gen))\n",
    "                output.append(i2o[p_gen.index(max(p_gen))])\n",
    "            else:\n",
    "                prev_mode = 1\n",
    "                prev_tok = 0\n",
    "                output.append(input_string[p_copy.index(max(p_copy))])\n",
    "            if output[-1] == eos:\n",
    "                break\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dropout(model,dropout):\n",
    "    model.DEC_RNN.set_dropout(dropout)\n",
    "    model.ENC_RNN_F.set_dropout(dropout)\n",
    "    model.ENC_RNN_B.set_dropout(dropout)\n",
    "    \n",
    "    \n",
    "set_dropout(copy_network,0)\n",
    "\n",
    "def translate_sample(model,input_string,type_string,embedded_string,mode_temp=1.0,gen_temp=1.0,copy_temp=1.0,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        numbered = [is_number(s) for s in input_string]\n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           e,\n",
    "                                           model.type_embeddings[type_o2i[t]]]) for n,e,t in zip(numbered,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_string)]\n",
    "        encoded_string_f = model._encode_string(embedded_string,model.ENC_RNN_F)\n",
    "        encoded_string_b = model._encode_string(list(reversed(embedded_string)),model.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = model.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(model.enc_state_size+model.output_embedding_size+2)\n",
    "            )\n",
    "        probs = []\n",
    "        for _ in range(max_len):\n",
    "            attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.attention_w1, model.attention_w2,model.attention_v)\n",
    "            _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.copy_w1, model.copy_w2,model.copy_v)\n",
    "            \n",
    "            mode_vec = np.zeros(2)\n",
    "            mode_vec[prev_mode] = 1\n",
    "            rnn_input = dy.concatenate([attended_encoding,\n",
    "                                        model.output_embeddings[prev_tok],\n",
    "                                        dy.inputTensor(mode_vec)\n",
    "                                       ])\n",
    "            \n",
    "            rnn_state = rnn_state.add_input(rnn_input)\n",
    "            \n",
    "            p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "            if mode_temp != 0:\n",
    "                mode_prob = dy.softmax(p_mode/mode_temp).value()\n",
    "                prev_mode = np.argmax(np.random.multinomial(1,mode_prob))\n",
    "            else:\n",
    "                mode_prob = dy.softmax(p_mode).value()\n",
    "                prev_mode = np.argmax(mode_prob)\n",
    "            \n",
    "            if prev_mode == 0:\n",
    "                \n",
    "                p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "                orig_prob = dy.softmax(p_gen).value()\n",
    "                if gen_temp != 0:\n",
    "                    gen_prob = dy.softmax(p_gen/gen_temp).value()\n",
    "                \n",
    "                    gen_prob = gen_prob/np.sum(gen_prob)\n",
    "                    prev_tok = np.argmax(np.random.multinomial(1,gen_prob))\n",
    "                else:\n",
    "                    prev_tok = np.argmax(orig_prob)\n",
    "                orig_prob =orig_prob/np.sum(orig_prob)\n",
    "                output.append(i2o[prev_tok])\n",
    "                gen_prob = orig_prob[prev_tok]\n",
    "            else:\n",
    "                \n",
    "                orig_prob = p_copy.value()             \n",
    "                orig_prob = orig_prob/np.sum(orig_prob)\n",
    "                if gen_temp != 0:\n",
    "                    gen_prob = dy.softmax(p_copy/copy_temp).value()                \n",
    "                    gen_prob = gen_prob/np.sum(gen_prob)\n",
    "                    copy_tok = np.argmax(np.random.multinomial(1,gen_prob))\n",
    "                else:\n",
    "                    copy_tok = np.argmax(orig_prob)          \n",
    "                               \n",
    "                prev_tok = 0\n",
    "                output.append(input_string[copy_tok])\n",
    "                gen_prob= orig_prob[copy_tok]\n",
    "            if output[-1] == eos:\n",
    "                break\n",
    "            probs.append(mode_prob[prev_mode])\n",
    "            probs.append(gen_prob)\n",
    "        return output,probs\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "i2o = {i:o for o,i in o2i.items()}\n",
    "\n",
    "\n",
    "def translate_beam_search(model,input_string,type_string,embedded_string,beam_width=3,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        numbered = [is_number(s) for s in input_string]\n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           e,\n",
    "                                           model.type_embeddings[type_o2i[t]]]) for n,e,t in zip(numbered,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_string)]\n",
    "        encoded_string_f = model._encode_string(embedded_string,model.ENC_RNN_F)\n",
    "        encoded_string_b = model._encode_string(list(reversed(embedded_string)),model.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = model.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(model.enc_state_size+model.output_embedding_size+2)\n",
    "            )\n",
    "        \n",
    "        beams = [(0,0,[],rnn_state,prev_mode,prev_tok)]\n",
    "        for _ in range(max_len):\n",
    "            potentials = []\n",
    "            for score,sum_score,output, rnn_state, prev_mode,prev_tok in beams:\n",
    "                \n",
    "                if prev_tok == o2i[eos]:\n",
    "                    potentials.append((score,sum_score,\n",
    "                                    output,rnn_state,prev_mode,prev_tok))\n",
    "                    continue\n",
    "                    \n",
    "                attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                           model.attention_w1, model.attention_w2,model.attention_v)\n",
    "                _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                           model.copy_w1, model.copy_w2,model.copy_v)\n",
    "\n",
    "                mode_vec = np.zeros(2)\n",
    "                mode_vec[prev_mode] = 1\n",
    "                rnn_input = dy.concatenate([attended_encoding,\n",
    "                                            model.output_embeddings[prev_tok],\n",
    "                                            dy.inputTensor(mode_vec)\n",
    "                                           ])\n",
    "\n",
    "\n",
    "\n",
    "                rnn_state = rnn_state.add_input(rnn_input)\n",
    "\n",
    "                p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "\n",
    "                p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "\n",
    "                p_mode = dy.softmax(p_mode).value()\n",
    "                p_copy = p_copy.value()\n",
    "                p_gen = dy.softmax(p_gen).value()\n",
    "                options = []\n",
    "                \n",
    "                \n",
    "                probs = [(p,i) for i,p in enumerate(p_gen)]\n",
    "                probs = sorted(probs,reverse=True)[:beam_width]\n",
    "                \n",
    "                for p,i in probs:\n",
    "                    sum_score_ = sum_score+np.log(p_mode[0])+np.log(p)\n",
    "                    score = sum_score_/(len(output)+1)\n",
    "                    options.append((score,sum_score_,\n",
    "                                    output + [i2o[i]],rnn_state,0,i))\n",
    "\n",
    "                probs = [(p,i) for i,p in enumerate(p_copy)]\n",
    "                probs = sorted(probs,reverse=True)[:beam_width]\n",
    "\n",
    "                for p,i in probs:\n",
    "                    sum_score_ = sum_score+np.log(p_mode[1])+np.log(p)\n",
    "                    score = sum_score_/(len(output)+1)\n",
    "                    options.append((score,sum_score_,\n",
    "                                    output + [input_string[i]],rnn_state,1,0))\n",
    "                \n",
    "                \n",
    "                options = sorted(options,reverse=True)\n",
    "                options = options[:beam_width]\n",
    "                potentials += options\n",
    "                \n",
    "            beams = sorted(potentials,reverse=True)[:beam_width]\n",
    "            \n",
    "                    \n",
    "        return beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.010838810535067855, -0.4877464740780535, ['[[$Move:]]', '[[initial_attack]]', '[[$Move:]]', '[[introduce_task]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available_for_urgent_task]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available_to_pick_up_gift_cards]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[provide_information]]', '[[$KEY:]]', '[[scam.gift_cards.brand]]', '[[$VALUE:]]', 'iTunes', '[[$KEY:]]', '[[scam.gift_cards.denomination]]', '[[$VALUE:]]', '$', '50', '[[$KEY:]]', '[[scam.gift_cards.introduced]]', '[[$VALUE:]]', 'True', '[[$KEY:]]', '[[scam.gift_cards.number]]', '[[$VALUE:]]', '15', '[[$KEY:]]', '[[status.on_the_go]]', '[[$VALUE:]]', 'True', '[[$KEY:]]', '[[status.on_the_go]]', '[[$VALUE:]]', '[[CLS]]'], <_dynet.RNNState object at 0x7f35784a2458>, 0, 10)\n"
     ]
    }
   ],
   "source": [
    "def prepare_sentence(sentence):\n",
    "    type_string = ['$FROM_FNAME', '$FROM_LNAME', '$FROM_EMAIL', '$TO_FNAME', '$TO_LNAME', '$TO_EMAIL', \n",
    "                   '$YEAR', '$MONTH', '$DAY', '$HOUR', '$MINUTE', '$GAP']\n",
    "\n",
    "    type_string = type_string + ['$BODY']*(len(sentence)-len(type_string))\n",
    "    embedded = elmo.embed_sentence(sentence)\n",
    "    return type_string,embedded\n",
    "\n",
    "\n",
    "\n",
    "sentence =['James', 'Ancelet', 'MjIDf@tCoTs.com', 'Patricia', 'Tikalsky', 'zleDT@PBRam.com', \n",
    "           '2019', '8', '10', '8', '1', '$N/A', \n",
    "           'I','need','you','to',\n",
    "           'buy', '15', '$', '50', 'iTunes', 'gift', 'cards', 'for', 'me', 'ASAP', '.',\n",
    "           'I','need','you','to', 'do','this'\n",
    "           '\\n', '-', 'James', ]\n",
    "\n",
    "type_string, embedded = prepare_sentence(sentence)\n",
    "\n",
    "beams = translate_beam_search(copy_network,sentence,type_string,embedded,\n",
    "                      beam_width=10,max_len=200,eos='[[CLS]]')\n",
    "print(beams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[[$Move:]]', '[[initial_attack]]', '[[$Move:]]', '[[introduce_task]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available_for_urgent_task]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available_to_pick_up_gift_cards]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[provide_information]]', '[[$KEY:]]', '[[scam.gift_cards.brand]]', '[[$VALUE:]]', 'iTunes', '[[$KEY:]]', '[[scam.gift_cards.denomination]]', '[[$VALUE:]]', '$', '50', '[[$KEY:]]', '[[scam.gift_cards.introduced]]', '[[$VALUE:]]', 'True', '[[$KEY:]]', '[[scam.gift_cards.number]]', '[[$VALUE:]]', '15', '[[$KEY:]]', '[[status.on_the_go]]', '[[$VALUE:]]', 'True', '[[$KEY:]]', '[[status.on_the_go]]', '[[$VALUE:]]', '[[CLS]]']\n",
      "-0.007844569707767682\n",
      "['[[$Move:]]', '[[initial_attack]]', '[[$Move:]]', '[[introduce_task]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available_for_urgent_task]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[answer_are_you_available_to_pick_up_gift_cards]]', '[[$ObligationPushed:]]', 'zleDT@PBRam.com', '$&', '[[provide_information]]', '[[$KEY:]]', '[[scam.gift_cards.brand]]', '[[$VALUE:]]', 'iTunes', '[[$KEY:]]', '[[scam.gift_cards.denomination]]', '[[$VALUE:]]', '$', '50', '[[$KEY:]]', '[[scam.gift_cards.introduced]]', '[[$VALUE:]]', 'True', '[[$KEY:]]', '[[scam.gift_cards.number]]', '[[$VALUE:]]', '15', '[[$KEY:]]', '[[status.on_the_go]]', '[[$VALUE:]]', 'True', '[[$KEY:]]', '[[status.on_the_go]]', '[[$VALUE:]]', '[[CLS]]']\n",
      "-0.007888641557883623\n",
      "The closer the score is to 0, the better\n"
     ]
    }
   ],
   "source": [
    "#Sample and take the best\n",
    "best_score = -np.inf\n",
    "best = None\n",
    "for _ in range(20):\n",
    "    output,probs = translate_sample(copy_network,  sentence,type_string,\n",
    "                                    embedded,\n",
    "                                    gen_temp=0.1,\n",
    "                                    mode_temp=0.1,\n",
    "                                    copy_temp=0.1,max_len=200)\n",
    "    score = np.sum(np.log(probs))/len(output)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best = output\n",
    "print(output)\n",
    "print(best_score)\n",
    "\n",
    "#Greedy Decoding\n",
    "output,probs = translate_sample(copy_network,  sentence,type_string,\n",
    "                                embedded,\n",
    "                                gen_temp=0,\n",
    "                                mode_temp=0,\n",
    "                                copy_temp=0,max_len=200)\n",
    "score = np.sum(np.log(probs))/len(output)\n",
    "print(output)\n",
    "print(score)\n",
    "\n",
    "print('The closer the score is to 0, the better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, -2, -3]\n"
     ]
    }
   ],
   "source": [
    "a = [0,-1,-2,-3]\n",
    "print(sorted(a,reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
