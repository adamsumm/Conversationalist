{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import _dynet\n",
    "import sys \n",
    "import numpy as np\n",
    "sys.argv.append('--dynet-devices')\n",
    "sys.argv.append('GPU:0')\n",
    "\n",
    "dyparams = _dynet.DynetParams()\n",
    "\n",
    "# Fetch the command line arguments (optional)\n",
    "dyparams.from_args()\n",
    "\n",
    "# Set some parameters manualy (see the command line arguments documentation)\n",
    "dyparams.set_mem(2048*5)\n",
    "dyparams.set_random_seed(666)\n",
    "# Initialize with the given parameters\n",
    "dyparams.init() # or init_from_params(dyparams)\n",
    "\n",
    "import dynet as dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_file = 'elmo_embedded_training_data_merged_130k_0_1.pkl'\n",
    "embedded_data = pickle.load(open(data_file,'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "type_vocab = set()\n",
    "for thread in embedded_data:\n",
    "    thread = thread[0]\n",
    "    for message,type,output in thread:\n",
    "        type_vocab |= set(type)\n",
    "        vocab |= set(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = set()\n",
    "safe = ['$&']\n",
    "for v in vocab:\n",
    "    if '[[' not in v and v not in safe:\n",
    "        to_remove.add(v)\n",
    "vocab -= to_remove\n",
    "\n",
    "vocab |= set(['<START>','!','<UNK>','True','False'])\n",
    "o2i = {o:i for i,o in enumerate(sorted(vocab))}\n",
    "i2o = {i:o for i,o in enumerate(sorted(vocab))}\n",
    "type_o2i = {o:i for i,o in enumerate(sorted(type_vocab))}\n",
    "type_i2o = {i:o for i,o in enumerate(sorted(type_vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sorted(['$_','$&'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "copy_data = []\n",
    "for thread in embedded_data:\n",
    "    thread_gen = []\n",
    "    thread_gc = []\n",
    "    thread_cop = []\n",
    "    text_thread = thread[0]\n",
    "    for message,type,output in text_thread:\n",
    "        gc = []\n",
    "        gen = []\n",
    "        cop = []\n",
    "        \n",
    "        for t in output:\n",
    "            t = t.replace('\\\\n','\\n')\n",
    "            ts = t.split('\\n\\n')\n",
    "            t = []\n",
    "            for t_ in ts:\n",
    "                t += t_.split('\\n')\n",
    "            ts = t\n",
    "            for t in ts:\n",
    "                if t == '':\n",
    "                    continue\n",
    "                if t in o2i:\n",
    "                    gc.append(0)\n",
    "                    gen.append(o2i[t])\n",
    "                    cop.append(0)\n",
    "                elif t not in message:\n",
    "                    gc.append(0)\n",
    "                    gen.append(o2i['<UNK>'])\n",
    "                    cop.append(0)                    \n",
    "                else:\n",
    "                    gc.append(1)\n",
    "                    gen.append(0)\n",
    "                    cop.append(message.index(t))\n",
    "        thread_gen.append(gen)\n",
    "        thread_gc.append(gc)\n",
    "        thread_cop.append(cop)\n",
    "        if 'LYDkK@Kjseh.com' in message:\n",
    "            print(message,cop,len(message))\n",
    "    all_data.append(list(zip([m[0] for m in thread[0]],[m[1] for m in thread[0]],[m[2] for m in thread[0]], thread[1],thread_gen,thread_gc,thread_cop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "class CopyNetwork:\n",
    "    def __init__(self, enc_layers, dec_layers, type_embeddings_size,embeddings_size, \n",
    "                 enc_state_size, dec_state_size,output_embedding_size, vocab_size, dropout = 0.1):\n",
    "        self.model = dy.Model()\n",
    "        self.type_embeddings = self.model.add_lookup_parameters((len(type_o2i), type_embeddings_size))\n",
    "        self.output_embeddings = self.model.add_lookup_parameters((vocab_size, output_embedding_size))\n",
    "       \n",
    "        # the rnns\n",
    "        #1 for type + 1 for history + obv\n",
    "        self.ENC_RNN_F = dy.LSTMBuilder(enc_layers, 2+type_embeddings_size+embeddings_size, enc_state_size/2, self.model)\n",
    "        self.ENC_RNN_F.set_dropout(dropout)\n",
    "        self.ENC_RNN_B = dy.LSTMBuilder(enc_layers, 2+type_embeddings_size+embeddings_size, enc_state_size/2, self.model)\n",
    "        self.ENC_RNN_B.set_dropout(dropout)\n",
    "        \n",
    "        self.DEC_RNN = dy.LSTMBuilder(dec_layers, enc_state_size+output_embedding_size+2, dec_state_size, self.model)\n",
    "        self.DEC_RNN.set_dropout(dropout)\n",
    "        \n",
    "        # attention weights\n",
    "        self.attention_w1 = self.model.add_parameters((enc_state_size, enc_state_size))\n",
    "        self.attention_w2 = self.model.add_parameters((enc_state_size, dec_state_size))\n",
    "        self.attention_v = self.model.add_parameters((1, enc_state_size))\n",
    "\n",
    "        \n",
    "        self.copy_w1 = self.model.add_parameters((enc_state_size, enc_state_size))\n",
    "        self.copy_w2 = self.model.add_parameters((enc_state_size, dec_state_size))\n",
    "        self.copy_v = self.model.add_parameters((1, enc_state_size))\n",
    "\n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.mode_w = self.model.add_parameters((2, dec_state_size))\n",
    "        self.mode_b = self.model.add_parameters((2))\n",
    "        \n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.output_w = self.model.add_parameters((vocab_size, dec_state_size))\n",
    "        self.output_b = self.model.add_parameters((vocab_size))\n",
    "        \n",
    "        self.enc_state_size = enc_state_size\n",
    "        self.type_embeddings_size = type_embeddings_size\n",
    "        self.embeddings_size = embeddings_size\n",
    "        self.output_embedding_size = output_embedding_size\n",
    "    def _run_rnn(self, init_state, input_vecs):\n",
    "        s = init_state\n",
    "\n",
    "        states = s.add_inputs(input_vecs)\n",
    "        rnn_outputs = [s.output() for s in states]\n",
    "        return rnn_outputs\n",
    "    def _encode_string(self, embedded_string,RNN):\n",
    "        initial_state = RNN.initial_state()\n",
    "\n",
    "        # run_rnn returns all the hidden state of all the slices of the RNN\n",
    "        hidden_states = self._run_rnn(initial_state, embedded_string)\n",
    "\n",
    "        return hidden_states\n",
    "    \n",
    "    def _attend(self, input_vectors, state, w1, w2,v ):\n",
    "        attention_weights = []\n",
    "\n",
    "        w2dt = w2 * state.h()[-1]\n",
    "        for input_vector in input_vectors:\n",
    "            \n",
    "            attention_weight = v * dy.tanh(w1 * input_vector + w2dt)\n",
    "            attention_weights.append(attention_weight)\n",
    "        attention_weights = dy.softmax(dy.concatenate(attention_weights))\n",
    "\n",
    "        output_vectors = dy.esum(\n",
    "            [vector * attention_weight for vector, attention_weight in zip(input_vectors, attention_weights)])\n",
    "        return output_vectors, attention_weights\n",
    "   \n",
    "    def _embed(self,pos,pos_embed):\n",
    "        return [pos_embed[p] for p in pos]\n",
    "    \n",
    "    def get_probs(self, w, b, rnn):\n",
    "        return w*rnn+b\n",
    "    \n",
    "    def get_loss(self, history_string,input_string,type_string,embedded_string,output_modes, output_generate, output_copy,\n",
    "                 dropout=0.1,teacher_forcing_=lambda : True,copy_loss_modifier=1.0):\n",
    "        \n",
    "        embedded_string = embedded_string\n",
    "        \n",
    "        \n",
    "        #embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        #dropped = [0 if random.random()<dropout else 1 for _ in embedded_string]\n",
    "        #embedded_string = [dy.inputTensor(e*d) for e,d in zip(embedded_string,dropped)]\n",
    "        dropouted = []\n",
    "        dropped = []\n",
    "        numbered = []\n",
    "        type_dropped = []\n",
    "        history_dropped = []\n",
    "        for i,(s,t,e,h) in enumerate(zip(input_string,type_string,embedded_string,history_string)):\n",
    "            if random.random()<dropout or i in output_copy or t != '$BODY':\n",
    "                dropouted.append(dy.inputTensor(e))\n",
    "                numbered.append(is_number(s))\n",
    "                type_dropped.append(t)\n",
    "                history_dropped.append(h)\n",
    "            else:\n",
    "                dropped.append(i)\n",
    "        dropped_copy = []\n",
    "        for d in output_copy:\n",
    "            if d != 0:\n",
    "                neg = 0\n",
    "                for d_i in dropped:\n",
    "                    if d_i < d:\n",
    "                        neg -= 1\n",
    "                d += neg\n",
    "            dropped_copy.append(d)\n",
    "        output_copy = dropped_copy    \n",
    "        embedded_string = dropouted\n",
    "        \n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           dy.inputTensor(np.array([h])),\n",
    "                                           e,\n",
    "                                           self.type_embeddings[type_o2i[t]]]) for n,h,e,t in zip(numbered,\n",
    "                                                                                                history_dropped,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_dropped)]\n",
    "        encoded_string_f = self._encode_string(embedded_string,self.ENC_RNN_F)\n",
    "        encoded_string_b = self._encode_string(list(reversed(embedded_string)),self.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        \n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = self.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(self.enc_state_size+self.output_embedding_size+2)\n",
    "            )\n",
    "        teacher_forcing = True\n",
    "        for mode,gen,copy in zip(output_modes,output_generate,output_copy):\n",
    "            attended_encoding,_ = self._attend(encoded_string, rnn_state, \n",
    "                                                       self.attention_w1, self.attention_w2,self.attention_v)\n",
    "            _,p_copy = self._attend(encoded_string, rnn_state, \n",
    "                                                       self.copy_w1, self.copy_w2,self.copy_v)\n",
    "            \n",
    "            mode_vec = np.zeros(2)\n",
    "            mode_vec[prev_mode] = 1\n",
    "            rnn_input = dy.concatenate([attended_encoding,\n",
    "                                        self.output_embeddings[prev_tok],\n",
    "                                        dy.inputTensor(mode_vec)\n",
    "                                       ])\n",
    "            \n",
    "            \n",
    "            \n",
    "            rnn_state = rnn_state.add_input(rnn_input)\n",
    "            \n",
    "            p_mode = self.get_probs(self.mode_w,self.mode_b,rnn_state.output())\n",
    "            \n",
    "            p_gen = self.get_probs(self.output_w,self.output_b,rnn_state.output())\n",
    "            \n",
    "            if teacher_forcing:\n",
    "                prev_mode = mode\n",
    "                prev_tok = gen\n",
    "            else:\n",
    "                prev_mode = p_mode.value()\n",
    "                prev_mode = prev_mode.index(max(prev_mode))\n",
    "                prev_tok = p_gen.value()\n",
    "                prev_tok = prev_tok.index(max(prev_tok))\n",
    "                \n",
    "                \n",
    "                \n",
    "            mode_err = dy.pickneglogsoftmax(p_mode, mode) \n",
    "            copy_err = dy.pickneglogsoftmax(p_copy,copy)*copy_loss_modifier  \n",
    "            gen_err = dy.pickneglogsoftmax(p_gen,gen)\n",
    "            \n",
    "            losses.append(mode_err)            \n",
    "            if  mode == 0:\n",
    "                losses.append(gen_err)\n",
    "            else:\n",
    "                losses.append(copy_err)\n",
    "                \n",
    "            if generate:\n",
    "                p_mode = p_mode.value()\n",
    "                p_copy = p_copy.value()\n",
    "                p_gen = p_gen.value()\n",
    "                if p_mode[0] > p_mode[1]:\n",
    "                    output.append(i2o[p_gen.index(max(p_gen))])\n",
    "                else:\n",
    "                    output.append(input_string[p_copy.index(max(p_copy))])\n",
    "        if generate:\n",
    "            print('IN:',' '.join(input_string))\n",
    "            print('OUT:',' '.join(output))\n",
    "            sys.stdout.flush()\n",
    "        return losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_network = CopyNetwork(3, 3,8, 1024, 1024, 1024, len(o2i),len(o2i),dropout = 0.35)\n",
    "lr = 0.01\n",
    "trainer = dy.AdamTrainer(copy_network.model,alpha = lr)\n",
    "random.shuffle(all_data)\n",
    "split = int(len(all_data)*0.7)\n",
    "all_data_training = all_data[:split]\n",
    "all_data_eval = all_data[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "lr = 0.00005\n",
    "\n",
    "\n",
    "\n",
    "trainer.learning_rate = lr\n",
    "i = 0\n",
    "best_eval = np.inf\n",
    "history_length = 2\n",
    "\n",
    "def run_thread(thread,update):\n",
    "    \n",
    "    history = []\n",
    "    all_loss = []\n",
    "    for message in thread:\n",
    "        dy.renew_cg()\n",
    "        history.append(message)\n",
    "        \n",
    "        I,type_string, output_string, embedded_string,gen,gOrC, cop = message\n",
    "        inputs = []\n",
    "        types = []\n",
    "        embeddings = []\n",
    "        histories = []\n",
    "\n",
    "        for h,m in enumerate(reversed(history[-history_length:])):\n",
    "            input_string,type_string, _, embedded_string,_,_,_ = m\n",
    "            inputs += input_string\n",
    "            types += [t for t,_ in zip(type_string,input_string)]\n",
    "            embeddings.append(embedded_string[2])\n",
    "            histories += [h]*len(input_string)\n",
    "\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        for e in embeddings:\n",
    "            break\n",
    "        loss = copy_network.get_loss(histories,inputs,types,embeddings, gOrC,gen,cop,\n",
    "                                     dropout=0.3+random.random()*0.7,\n",
    "                                    teacher_forcing_=lambda : random.random()<0.15,copy_loss_modifier=1.0)\n",
    "        loss = dy.esum(loss)\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "        all_loss.append(loss.value()/(2.0*len(gOrC)))\n",
    "    return all_loss\n",
    "for epoch in tqdm_notebook(range(500)):\n",
    "    print(f'EPOCH {epoch}')\n",
    "    \n",
    "    random.shuffle(all_data_training)\n",
    "    average_training = []\n",
    "    i = 0\n",
    "    for thread in tqdm_notebook(all_data_training):        \n",
    "        average_training += run_thread(thread,True)\n",
    "        i += len(average_training)\n",
    "        \n",
    "        if i > 100:\n",
    "            i -= 100\n",
    "            print(np.mean(average_training[:]),)\n",
    "            sys.stdout.flush()\n",
    "       \n",
    "    average_eval = []     \n",
    "    for thread in tqdm_notebook(all_data_eval):\n",
    "        average_eval += run_thread(thread,False)\n",
    "        \n",
    "    if np.mean(average_eval) < best_eval:\n",
    "        print('BEST: ',np.mean(average_eval[:]))\n",
    "        copy_network.model.save(f'Conversationalist_3_3_1024_512_1024_{history_length}_{data_file.split(\".\")[0]}.model')\n",
    "        \n",
    "    print('TRAINING: ',np.mean(average_training[:]))\n",
    "    print('EVAL: ',np.mean(average_eval[:]))\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(average_training)\n",
    "    plt.show()\n",
    "    plt.plot(average_eval)\n",
    "    plt.show()    \n",
    "    if epoch % 1 == 0:\n",
    "        lr = lr *0.97\n",
    "        print('decaying ', lr)\n",
    "        trainer.learning_rate = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN: Joshua Jakeway siSTh@GlkOv.com William Minge VtgrL@STldb.com 2019 4 17 14 15 202 50 , right . \n",
    "\n",
    " - Joshua \n",
    "\n",
    " Sent from my iPhone William Minge VtgrL@STldb.com Joshua Jakeway siSTh@GlkOv.com 2019 4 17 14 11 179 50 gift cards , right ? Just want to confirm . \n",
    "\n",
    " - William \n",
    "\n",
    " Sent from my iPhone Joshua Jakeway siSTh@GlkOv.com William Minge VtgrL@STldb.com 2019 4 17 14 8 158 Pay using the company card . \n",
    "\n",
    " - Joshua \n",
    "\n",
    " Sent from my iPhone\n",
    "OUT: [[$Move:]] [[confirm_gift_card_number]] [[$Move:]] [[provide_guidance]] [[$Move:]] [[provide_information]] [[$ObligationPushed:]] VtgrL@STldb.com $& [[provide_update]] [[$KEY:]] [[status.on_the_go]] [[$VALUE:]] True [[$KEY:]] [[status.on_the_go]] [[$VALUE:]] [[CLS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "lr = 0.00005\n",
    "\n",
    "\n",
    "\n",
    "trainer.learning_rate = lr\n",
    "i = 0\n",
    "best_eval = np.inf\n",
    "history_length = 3\n",
    "\n",
    "def run_thread(thread,update):\n",
    "    \n",
    "    history = []\n",
    "    all_loss = []\n",
    "    for message in thread:\n",
    "        dy.renew_cg()\n",
    "        history.append(message)\n",
    "        \n",
    "        I,type_string, output_string, embedded_string,gen,gOrC, cop = message\n",
    "        inputs = []\n",
    "        types = []\n",
    "        embeddings = []\n",
    "        histories = []\n",
    "\n",
    "        for h,m in enumerate(reversed(history[-history_length:])):\n",
    "            input_string,type_string, _, embedded_string,_,_,_ = m\n",
    "            inputs += input_string\n",
    "            types += [t for t,_ in zip(type_string,input_string)]\n",
    "            embeddings.append(embedded_string[2])\n",
    "            histories += [h]*len(input_string)\n",
    "\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        for e in embeddings:\n",
    "            break\n",
    "        loss = copy_network.get_loss(histories,inputs,types,embeddings, gOrC,gen,cop,\n",
    "                                     dropout=0.3+random.random()*0.7,\n",
    "                                    teacher_forcing_=lambda : random.random()<0.15,copy_loss_modifier=1.0)\n",
    "        loss = dy.esum(loss)\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "        all_loss.append(loss.value()/(2.0*len(gOrC)))\n",
    "    return all_loss\n",
    "for epoch in  tqdm_notebook(range(500)):\n",
    "    print(f'EPOCH {epoch}')\n",
    "    \n",
    "    random.shuffle(all_data_training)\n",
    "    average_training = []\n",
    "    for thread in tqdm_notebook(all_data_training):\n",
    "        \n",
    "        history = []\n",
    "        print(len(thread))\n",
    "        for message in thread:\n",
    "            dy.renew_cg()\n",
    "            history.append(message)\n",
    "            i += 1\n",
    "            #list(zip([m[0] for m in thread[0]],[m[1] for m in thread[0]], thread[1],thread_gen,thread_gc,thread_cop)))\n",
    "            \n",
    "            I,type_string, output_string, embedded_string,gen,gOrC, cop = message\n",
    "            inputs = []\n",
    "            types = []\n",
    "            embeddings = []\n",
    "            histories = []\n",
    "            \n",
    "            for h,m in enumerate(reversed(history[-history_length:])):\n",
    "                input_string,type_string, _, embedded_string,_,_,_ = m\n",
    "                inputs += input_string\n",
    "                types += [t for t,_ in zip(type_string,input_string)]\n",
    "                embeddings.append(embedded_string[2])\n",
    "                histories += [h]*len(input_string)\n",
    "                \n",
    "            embeddings = np.vstack(embeddings)\n",
    "            for e in embeddings:\n",
    "                break\n",
    "            loss = copy_network.get_loss(histories,inputs,types,embeddings, gOrC,gen,cop,\n",
    "                                         dropout=0.3+random.random()*0.7,\n",
    "                                        teacher_forcing_=lambda : random.random()<0.15,copy_loss_modifier=1.0)\n",
    "            loss = dy.esum(loss)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            average_training.append(loss.value()/(2.0*len(gOrC)))\n",
    "            if i % 100 == 0:\n",
    "\n",
    "                print(np.mean(average_training[:]),)\n",
    "                sys.stdout.flush()\n",
    "    average_eval = []\n",
    "    for thread in tqdm_notebook(all_data_eval):\n",
    "        history = []\n",
    "        for message in thread:\n",
    "            dy.renew_cg()\n",
    "            history.insert(0,message)\n",
    "            i += 1\n",
    "             \n",
    "            I,T,_,E,gen,gOrC, cop = message\n",
    "            inputs = []\n",
    "            types = []\n",
    "            embeddings = []\n",
    "            histories = []\n",
    "            \n",
    "            \n",
    "            for h,m in enumerate(reversed(history[-history_length:])):\n",
    "                input_string,type_string, _, embedded_string,_,_,_ = m\n",
    "                inputs += input_string\n",
    "                types += [t for t,_ in zip(type_string,input_string)]\n",
    "                embeddings.append(embedded_string[2])\n",
    "                histories += [h]*len(input_string)\n",
    "                \n",
    "                \n",
    "            embeddings = np.vstack(embeddings)\n",
    "            loss = copy_network.get_loss(histories,inputs,types,embeddings, gOrC,gen,cop,\n",
    "                                         dropout=0.3+random.random()*0.7,\n",
    "                                        teacher_forcing_=lambda : random.random()<0.15,copy_loss_modifier=1.0)\n",
    "            loss = dy.esum(loss)\n",
    "            average_eval.append(loss.value()/(2.0*len(gOrC)))\n",
    "    if np.mean(average_eval) < best_eval:\n",
    "        print('BEST: ',np.mean(average_eval[:]))\n",
    "        copy_network.model.save(f'Conversationalist_3_3_1024_512_1024_{history_length}_{data_file.split(\".\")[0]}.model')\n",
    "    print('TRAINING: ',np.mean(average_training[:]))\n",
    "    print('EVAL: ',np.mean(average_eval[:]))\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(average_training)\n",
    "    plt.show()\n",
    "    plt.plot(average_eval)\n",
    "    plt.show()    \n",
    "    if epoch % 1 == 0:\n",
    "        lr = lr *0.97\n",
    "        print('decaying ', lr)\n",
    "        trainer.learning_rate = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histories,inputs,types,embeddings, gOrC,gen,cop)\n",
    "print(output_string)\n",
    "print(len(inputs))\n",
    "print(len(types))\n",
    "print(len(embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_network.model.save(f'Conversationalist_3_3_1024_1024_1024_1_{data_file.split(\".\")[0]}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((i2o,o2i,type_o2i,type_i2o),open('vocab.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "elmo = ElmoEmbedder(options_file='~/DownloadedModels/Elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json',\n",
    "                    weight_file='~/DownloadedModels/Elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\n",
    "                    cuda_device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "i2o = {i:o for o,i in o2i.items()}\n",
    "\n",
    "\n",
    "def translate(model,input_string,type_string,embedded_string,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        numbered = [is_number(s) for s in input_string]\n",
    "        embedded_string = embedded_string[2]\n",
    "        #embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           e,\n",
    "                                           model.type_embeddings[type_o2i[t]]]) for n,e,t in zip(numbered,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_string)]\n",
    "        encoded_string_f = model._encode_string(embedded_string,model.ENC_RNN_F)\n",
    "        encoded_string_b = model._encode_string(list(reversed(embedded_string)),model.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = model.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(model.enc_state_size+model.output_embedding_size+2)\n",
    "            )\n",
    "        for _ in range(max_len):\n",
    "            attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.attention_w1, model.attention_w2,model.attention_v)\n",
    "            _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.copy_w1, model.copy_w2,model.copy_v)\n",
    "            \n",
    "            mode_vec = np.zeros(2)\n",
    "            mode_vec[prev_mode] = 1\n",
    "            rnn_input = dy.concatenate([attended_encoding,\n",
    "                                        model.output_embeddings[prev_tok],\n",
    "                                        dy.inputTensor(mode_vec)\n",
    "                                       ])\n",
    "            \n",
    "            \n",
    "            \n",
    "            rnn_state = rnn_state.add_input(rnn_input)\n",
    "            \n",
    "            p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "            \n",
    "            p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "            \n",
    "            p_mode = p_mode.value()\n",
    "            p_copy = p_copy.value()\n",
    "            p_gen = p_gen.value()\n",
    "            \n",
    "            \n",
    "            if p_mode[0] > p_mode[1]:\n",
    "                prev_mode = 0\n",
    "                prev_tok = p_gen.index(max(p_gen))\n",
    "                output.append(i2o[p_gen.index(max(p_gen))])\n",
    "            else:\n",
    "                prev_mode = 1\n",
    "                prev_tok = 0\n",
    "                output.append(input_string[p_copy.index(max(p_copy))])\n",
    "            if output[-1] == eos:\n",
    "                break\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def set_dropout(model,dropout):\n",
    "    model.DEC_RNN.set_dropout(dropout)\n",
    "    model.ENC_RNN_F.set_dropout(dropout)\n",
    "    model.ENC_RNN_B.set_dropout(dropout)\n",
    "    \n",
    "    \n",
    "set_dropout(copy_network,0)\n",
    "\n",
    "def translate_sample(model,input_string,type_string,embedded_string,mode_temp=1.0,gen_temp=1.0,copy_temp=1.0,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        numbered = [is_number(s) for s in input_string]\n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           e,\n",
    "                                           model.type_embeddings[type_o2i[t]]]) for n,e,t in zip(numbered,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_string)]\n",
    "        encoded_string_f = model._encode_string(embedded_string,model.ENC_RNN_F)\n",
    "        encoded_string_b = model._encode_string(list(reversed(embedded_string)),model.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = model.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(model.enc_state_size+model.output_embedding_size+2)\n",
    "            )\n",
    "        probs = []\n",
    "        for _ in range(max_len):\n",
    "            attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.attention_w1, model.attention_w2,model.attention_v)\n",
    "            _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.copy_w1, model.copy_w2,model.copy_v)\n",
    "            \n",
    "            mode_vec = np.zeros(2)\n",
    "            mode_vec[prev_mode] = 1\n",
    "            rnn_input = dy.concatenate([attended_encoding,\n",
    "                                        model.output_embeddings[prev_tok],\n",
    "                                        dy.inputTensor(mode_vec)\n",
    "                                       ])\n",
    "            \n",
    "            rnn_state = rnn_state.add_input(rnn_input)\n",
    "            \n",
    "            p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "            if mode_temp != 0:\n",
    "                mode_prob = dy.softmax(p_mode/mode_temp).value()\n",
    "                prev_mode = np.argmax(np.random.multinomial(1,mode_prob))\n",
    "            else:\n",
    "                mode_prob = dy.softmax(p_mode).value()\n",
    "                prev_mode = np.argmax(mode_prob)\n",
    "            \n",
    "            if prev_mode == 0:\n",
    "                \n",
    "                p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "                orig_prob = dy.softmax(p_gen).value()\n",
    "                if gen_temp != 0:\n",
    "                    gen_prob = dy.softmax(p_gen/gen_temp).value()\n",
    "                \n",
    "                    gen_prob = gen_prob/np.sum(gen_prob)\n",
    "                    prev_tok = np.argmax(np.random.multinomial(1,gen_prob))\n",
    "                else:\n",
    "                    prev_tok = np.argmax(orig_prob)\n",
    "                orig_prob =orig_prob/np.sum(orig_prob)\n",
    "                output.append(i2o[prev_tok])\n",
    "                gen_prob = orig_prob[prev_tok]\n",
    "            else:\n",
    "                \n",
    "                orig_prob = dy.softmax(p_copy).value()             \n",
    "                orig_prob = orig_prob/np.sum(orig_prob)\n",
    "                if gen_temp != 0:\n",
    "                    gen_prob = dy.softmax(p_copy/copy_temp).value()                \n",
    "                    gen_prob = gen_prob/np.sum(gen_prob)\n",
    "                    copy_tok = np.argmax(np.random.multinomial(1,gen_prob))\n",
    "                else:\n",
    "                    copy_tok = np.argmax(orig_prob)          \n",
    "                               \n",
    "                prev_tok = 0\n",
    "                output.append(input_string[copy_tok])\n",
    "                gen_prob= orig_prob[copy_tok]\n",
    "            if output[-1] == eos:\n",
    "                break\n",
    "            probs.append(mode_prob[prev_mode])\n",
    "            probs.append(gen_prob)\n",
    "        return output,probs\n",
    "type_string = ['$FROM_FNAME', '$FROM_LNAME', '$FROM_EMAIL', '$TO_FNAME', '$TO_LNAME', '$TO_EMAIL', '$YEAR', '$MONTH', '$DAY', '$HOUR', '$MINUTE', '$GAP']\n",
    "sentence = ['John', 'Davin', 'LWmow@SMAqB.com', 'Steven', 'Smalley', 'oFDvG@kIrPz.com', '2019', '10', '9', '7', '43', '$N/A',\n",
    "            'I', 'hope', 'you', \"'re\", 'available', 'at', 'the', 'moment', 'for', 'a', 'task', '(', 'urgent', ')', '?',\n",
    "            '\\n\\n', 'Let', 'me', 'know', 'either', 'way', 'as', 'soon', 'as', 'possible', '.',\n",
    "            'I', 'urgently', 'need', 'you', 'to', 'buy', 'some', 'gift', 'cards', 'for', 'me', 'ASAP', '.', \n",
    "            'Please', 'confirm', 'that', 'you', \"'re\", 'on', 'this', '.', '\\n\\n', '-', 'John', '\\n\\n', 'Sent', 'from', 'my', 'iPhone']\n",
    "sentence =['James', 'Ancelet', 'MjIDf@tCoTs.com', 'Patricia', 'Tikalsky', 'zleDT@PBRam.com', \n",
    "           '2019', '8', '10', '8', '1', '$N/A', \n",
    "          # 'Do', 'you', 'happen', 'to', 'be', 'available', 'immediately', 'to', 'do', 'something', 'for', 'me',\n",
    "          # '(', 'it', \"'s\", 'urgent', ')', '?', \n",
    "          # 'I', \"'m\", 'on', 'jury', 'duty', 'and', 'ca', \"n't\", 'talk', 'on', 'the', 'phone', ',', \n",
    "          # 'so', 'I', 'can', 'only', 'be', 'reached', 'via', 'email', '.',\n",
    "           'Go',\n",
    "           'buy', '15', '$', '50', 'iTunes', 'gift', 'cards', 'for', 'me', 'ASAP', '.',\n",
    "           'I','need','you','to', 'do','this'\n",
    "           '\\n', '-', 'James', ]\n",
    "\n",
    "  \n",
    "def prepare_sentence(sentence):\n",
    "    type_string = ['$FROM_FNAME', '$FROM_LNAME', '$FROM_EMAIL', '$TO_FNAME', '$TO_LNAME', '$TO_EMAIL', \n",
    "                   '$YEAR', '$MONTH', '$DAY', '$HOUR', '$MINUTE', '$GAP']\n",
    "\n",
    "    type_string = type_string + ['$BODY']*(len(sentence)-len(type_string))\n",
    "    embedded = elmo.embed_sentence(sentence)\n",
    "    return type_string,embedded\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "type_string, embedded = prepare_sentence(sentence)\n",
    "best_score = -np.inf\n",
    "best = None\n",
    "for _ in range(20):\n",
    "    output,probs = translate_sample(copy_network,  sentence,type_string,\n",
    "                                    embedded,\n",
    "                                    gen_temp=0.1,\n",
    "                                    mode_temp=0.1,\n",
    "                                    copy_temp=0.1,max_len=200)\n",
    "    score = np.sum(np.log(probs))/len(output)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best = output\n",
    "print(output)\n",
    "print(best_score)\n",
    "output,probs = translate_sample(copy_network,  sentence,type_string,\n",
    "                                embedded,\n",
    "                                gen_temp=0,\n",
    "                                mode_temp=0,\n",
    "                                copy_temp=0,max_len=200)\n",
    "score = np.sum(np.log(probs))/len(output)\n",
    "print(output)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "i2o = {i:o for o,i in o2i.items()}\n",
    "\n",
    "\n",
    "def translate_beam_search(model,input_string,type_string,embedded_string,beam_width=3,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        numbered = [is_number(s) for s in input_string]\n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           e,\n",
    "                                           model.type_embeddings[type_o2i[t]]]) for n,e,t in zip(numbered,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_string)]\n",
    "        encoded_string_f = model._encode_string(embedded_string,model.ENC_RNN_F)\n",
    "        encoded_string_b = model._encode_string(list(reversed(embedded_string)),model.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = model.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(model.enc_state_size+model.output_embedding_size+2)\n",
    "            )\n",
    "        \n",
    "        beams = [(0,0,[],rnn_state,prev_mode,prev_tok)]\n",
    "        for _ in range(max_len):\n",
    "            potentials = []\n",
    "            for score,sum_score,output, rnn_state, prev_mode,prev_tok in beams:\n",
    "                \n",
    "                if prev_tok == o2i[eos]:\n",
    "                    potentials.append((score,sum_score,\n",
    "                                    output,rnn_state,prev_mode,prev_tok))\n",
    "                    continue\n",
    "                    \n",
    "                attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                           model.attention_w1, model.attention_w2,model.attention_v)\n",
    "                _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                           model.copy_w1, model.copy_w2,model.copy_v)\n",
    "\n",
    "                mode_vec = np.zeros(2)\n",
    "                mode_vec[prev_mode] = 1\n",
    "                rnn_input = dy.concatenate([attended_encoding,\n",
    "                                            model.output_embeddings[prev_tok],\n",
    "                                            dy.inputTensor(mode_vec)\n",
    "                                           ])\n",
    "\n",
    "\n",
    "\n",
    "                rnn_state = rnn_state.add_input(rnn_input)\n",
    "\n",
    "                p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "\n",
    "                p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "\n",
    "                p_mode = dy.softmax(p_mode).value()\n",
    "                p_copy = p_copy.value()\n",
    "                p_gen = dy.softmax(p_gen).value()\n",
    "                options = []\n",
    "                \n",
    "                \n",
    "                probs = [(p,i) for i,p in enumerate(p_gen)]\n",
    "                probs = sorted(probs,reverse=True)[:beam_width]\n",
    "                \n",
    "                for p,i in probs:\n",
    "                    sum_score_ = sum_score+np.log(p_mode[0])+np.log(p)\n",
    "                    score = sum_score_/(len(output)+1)\n",
    "                    options.append((score,sum_score_,\n",
    "                                    output + [i2o[i]],rnn_state,0,i))\n",
    "\n",
    "                probs = [(p,i) for i,p in enumerate(p_copy)]\n",
    "                probs = sorted(probs,reverse=True)[:beam_width]\n",
    "\n",
    "                for p,i in probs:\n",
    "                    sum_score_ = sum_score+np.log(p_mode[1])+np.log(p)\n",
    "                    score = sum_score_/(len(output)+1)\n",
    "                    options.append((score,sum_score_,\n",
    "                                    output + [input_string[i]],rnn_state,1,0))\n",
    "                \n",
    "                \n",
    "                options = sorted(options,reverse=True)\n",
    "                options = options[:beam_width]\n",
    "                potentials += options\n",
    "                \n",
    "            beams = sorted(potentials,reverse=True)[:beam_width]\n",
    "            \n",
    "                    \n",
    "        return beams\n",
    "    \n",
    "def prepare_sentence(sentence):\n",
    "    type_string = ['$FROM_FNAME', '$FROM_LNAME', '$FROM_EMAIL', '$TO_FNAME', '$TO_LNAME', '$TO_EMAIL', \n",
    "                   '$YEAR', '$MONTH', '$DAY', '$HOUR', '$MINUTE', '$GAP']\n",
    "\n",
    "    type_string = type_string + ['$BODY']*(len(sentence)-len(type_string))\n",
    "    embedded = elmo.embed_sentence(sentence)\n",
    "    return type_string,embedded\n",
    "\n",
    "\n",
    "\n",
    "sentence =['James', 'Ancelet', 'MjIDf@tCoTs.com', 'Patricia', 'Tikalsky', 'zleDT@PBRam.com', \n",
    "           '2019', '8', '10', '8', '1', '$N/A', \n",
    "           'Go',\n",
    "           'buy', '15', '$', '50', 'iTunes', 'gift', 'cards', 'for', 'me', 'ASAP', '.',\n",
    "           'I','need','you','to', 'do','this'\n",
    "           '\\n', '-', 'James', ]\n",
    "\n",
    "type_string, embedded = prepare_sentence(sentence)\n",
    "\n",
    "beams = translate_beam_search(copy_network,sentence,type_string,embedded,\n",
    "                      beam_width=5,max_len=200,eos='[[CLS]]')\n",
    "for b in beams[:]:\n",
    "    print(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_nucleus_sample(model,input_string,type_string,embedded_string,mode_temp=1.0,gen_temp=1.0,copy_temp=1.0,nucleus=0.9,max_len=30,eos='[[CLS]]'):\n",
    "        dy.renew_cg()\n",
    "        numbered = [is_number(s) for s in input_string]\n",
    "        embedded_string = embedded_string[2]\n",
    "        embedded_string = [dy.inputTensor(e) for e in embedded_string]\n",
    "        \n",
    "        \n",
    "        embedded_string = [dy.concatenate([dy.inputTensor(np.array([n])),\n",
    "                                           e,\n",
    "                                           model.type_embeddings[type_o2i[t]]]) for n,e,t in zip(numbered,\n",
    "                                                                                                embedded_string,\n",
    "                                                                                                type_string)]\n",
    "        encoded_string_f = model._encode_string(embedded_string,model.ENC_RNN_F)\n",
    "        encoded_string_b = model._encode_string(list(reversed(embedded_string)),model.ENC_RNN_B)\n",
    "        encoded_string = [dy.concatenate([f,b]) for f,b in zip(encoded_string_f,reversed(encoded_string_b))]\n",
    "\n",
    "        mode_probs = []\n",
    "        gen_probs = []\n",
    "        copy_probs = []\n",
    "        \n",
    "        losses = []\n",
    "        generate = random.random() < 0.01\n",
    "        output = []\n",
    "        prev_mode = 0\n",
    "        prev_tok = o2i['<START>']\n",
    "        rnn_state = model.DEC_RNN.initial_state().add_input(\n",
    "                dy.vecInput(model.enc_state_size+model.output_embedding_size+2)\n",
    "            )\n",
    "        probs = []\n",
    "        for _ in range(max_len):\n",
    "            attended_encoding,_ = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.attention_w1, model.attention_w2,model.attention_v)\n",
    "            _,p_copy = model._attend(encoded_string, rnn_state, \n",
    "                                                       model.copy_w1, model.copy_w2,model.copy_v)\n",
    "            \n",
    "            mode_vec = np.zeros(2)\n",
    "            mode_vec[prev_mode] = 1\n",
    "            rnn_input = dy.concatenate([attended_encoding,\n",
    "                                        model.output_embeddings[prev_tok],\n",
    "                                        dy.inputTensor(mode_vec)\n",
    "                                       ])\n",
    "            \n",
    "            rnn_state = rnn_state.add_input(rnn_input)\n",
    "            \n",
    "            p_mode = model.get_probs(model.mode_w,model.mode_b,rnn_state.output())\n",
    "            if mode_temp != 0:\n",
    "                mode_prob = dy.softmax(p_mode/mode_temp).value()\n",
    "                prev_mode = np.argmax(np.random.multinomial(1,mode_prob))\n",
    "            else:\n",
    "                mode_prob = dy.softmax(p_mode).value()\n",
    "                prev_mode = np.argmax(mode_prob)\n",
    "            \n",
    "            if prev_mode == 0:\n",
    "                \n",
    "                p_gen = model.get_probs(model.output_w,model.output_b,rnn_state.output())\n",
    "                orig_prob = dy.softmax(p_gen).value()\n",
    "                if gen_temp != 0:\n",
    "                    gen_prob = dy.softmax(p_gen/gen_temp).value()                \n",
    "                    gen_prob = gen_prob/np.sum(gen_prob)\n",
    "                    \n",
    "                    gen_prob = [(p,i) for i,p in enumerate(gen_prob)]\n",
    "\n",
    "                    gen_prob = sorted(gen_prob,reverse=True)\n",
    "                    cum_prob = 0\n",
    "                    gen_prob_ = []\n",
    "                    indices = []\n",
    "                    for p,i in gen_prob:\n",
    "                        if cum_prob > nucleus:\n",
    "                            break\n",
    "                        gen_prob_.append(p)\n",
    "                        indices.append(i)\n",
    "                        cum_prob += p\n",
    "                    gen_prob_ = np.array(gen_prob_)/cum_prob\n",
    "                    if len(gen_prob_) >1:\n",
    "                        print('Gen', gen_prob_)\n",
    "                    prev_tok = indices[np.argmax(np.random.multinomial(1,gen_prob_))]\n",
    "                else:\n",
    "                    prev_tok = np.argmax(orig_prob)\n",
    "                    \n",
    "                \n",
    "                orig_prob =orig_prob/np.sum(orig_prob)\n",
    "                output.append(i2o[prev_tok])\n",
    "                gen_prob = orig_prob[prev_tok]\n",
    "            else:\n",
    "                \n",
    "                orig_prob = p_copy.value()             \n",
    "                orig_prob = orig_prob/np.sum(orig_prob)\n",
    "                if gen_temp != 0:\n",
    "                    gen_prob = p_copy.value()\n",
    "                    gen_prob = np.exp(np.log(gen_prob)/copy_temp)\n",
    "                    gen_prob = gen_prob/np.sum(gen_prob)\n",
    "                    gen_prob = [(p,i) for i,p in enumerate(gen_prob)]\n",
    "\n",
    "                    gen_prob = sorted(gen_prob,reverse=True)\n",
    "                    cum_prob = 0\n",
    "                    gen_prob_ = []\n",
    "                    indices = []\n",
    "                    for p,i in gen_prob:\n",
    "                        if cum_prob > nucleus:\n",
    "                            break\n",
    "                        gen_prob_.append(p)\n",
    "                        indices.append(i)\n",
    "                        cum_prob += p\n",
    "                    \n",
    "                    gen_prob_ = np.array(gen_prob_)/cum_prob\n",
    "                    if len(gen_prob_) >1:\n",
    "                        print('Copy', gen_prob_)\n",
    "                    copy_tok = indices[np.argmax(np.random.multinomial(1,gen_prob_))]\n",
    "                else:\n",
    "                    copy_tok = np.argmax(orig_prob)          \n",
    "                               \n",
    "                prev_tok = 0\n",
    "                output.append(input_string[copy_tok])\n",
    "                gen_prob= orig_prob[copy_tok]\n",
    "            if output[-1] == eos:\n",
    "                break\n",
    "            probs.append(mode_prob[prev_mode])\n",
    "            probs.append(gen_prob)\n",
    "        return output,probs\n",
    "    \n",
    "def set_dropout(model,dropout):\n",
    "    model.DEC_RNN.set_dropout(dropout)\n",
    "    model.ENC_RNN_F.set_dropout(dropout)\n",
    "    model.ENC_RNN_B.set_dropout(dropout)\n",
    "    \n",
    "    \n",
    "set_dropout(copy_network,0)\n",
    "    \n",
    "best_score = -np.inf\n",
    "best = None\n",
    "for _ in range(50):\n",
    "    output, probs = translate_nucleus_sample(copy_network,sentence,type_string,embedded,\n",
    "                      nucleus=0.9,max_len=200,eos='[[CLS]]')\n",
    "    score = np.sum(np.log(probs))/len(output)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best = output\n",
    "print(output)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thoughts on the data:\n",
    "#It gets Bed Bath & Beyond but not Bed , Bath & Beyond -- make it more robust to spelling differences\n",
    "#It also doesn't get Outback Steakhouse -- so maybe add more multi word gift card names\n",
    "\n",
    "#It still seems to be overfitting\n",
    "#e.g., \n",
    "#    'I','need','you','to',\n",
    "#           'buy', '457', '$', '50', 'Bed','Bath','&','Beyond', 'gift', 'cards', 'for', 'me', 'ASAP', '.',\n",
    "#           '\\n', '-', 'James', '\\n\\n', 'Sent', 'from', 'my', 'iPhone']\n",
    "# works but \n",
    "# 'Can', 'you', ...\n",
    "# doesn't\n",
    "\n",
    "\n",
    "print(all_data[0][0][0])\n",
    "print(all_data[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.3640618446714108e-11, 1.1083164132313719e-06, 1.8857741733250397e-11, 1.3196976318739576e-08, 1.225326221462253e-11, 9.422314555023724e-10, 1.1535195134986747e-07, 0.9999999999563177, 1.2778737349180107e-07, 3.751995254797341e-07, 3.333531359583222e-07, 5.723535090054632e-08, 1.2074775473289648e-08, 4.670662399492747e-09, 1.967804987128595e-10, 1.4175243208498506e-10, 9.109405480614336e-06, 1.8634605090886515e-10, 4.916721603106333e-11, 5.973859828538949e-08, 2.243133992714868e-07, 5.513519188965425e-07, 7.083992813975811e-08, 5.2531029590105224e-08, 2.608313174428328e-08, 7.00641815485009e-08, 2.122040500498444e-08, 3.8131691352691375e-08, 5.6287955942859065e-08, 2.2970600161179208e-07, 5.108544082773639e-08, 3.6798459722839858e-09, 2.0364517935446882e-10, 6.593096613977552e-10, 6.861888500118648e-09, 2.3426219695173565e-11, 1.5258417527711514e-06, 1.0125287163049123e-08, 1.4919654409278586e-07, 7.073738197225914e-10, 7.790397394555158e-09, 9.183113884100136e-09, 2.582737429272353e-09, 1.6410468824877222e-08, 1.5978417986581006e-09, 1.9619556344503147e-09, 1.3803174761553554e-07, 2.628892974755092e-10, 3.0569263001489684e-09, 6.579714757679253e-11, 1.0733344058081496e-08, 2.7581559028193095e-08, 3.1367170418628683e-08, 3.6238681373392987e-08, 2.290931031840497e-08, 5.303551534446905e-08, 5.598832892908799e-09, 1.7237956132790137e-08, 8.645185937551729e-09, 2.8855304021967843e-09, 8.095685031380281e-08, 2.327593806965199e-08, 1.0518557111171977e-08, 1.5701865969952374e-08, 1.4428753368635808e-08, 1.421675942920381e-07, 1.2294342667685022e-08, 1.058213138288223e-07, 1.4286517468852753e-08, 1.2074907280931212e-07, 1.0423292338858633e-08, 1.28734542848808e-08, 1.6960441538455674e-09, 6.553078583853081e-10, 8.345694639465493e-08]\n",
    "a = np.array(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
